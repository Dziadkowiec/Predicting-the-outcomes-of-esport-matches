{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RANDOM FORSET**\n",
    "\n",
    "Let's begin by importing nessesary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data and divide it into training and test sets. Note that in case of random forest model there is no need to scale the data with the Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('masterfile done.csv')\n",
    "\n",
    "X = df.iloc[:, 1:-2]\n",
    "y = df['future result']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify= y, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run a simple random forest model and see how it performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest accuracy  0.6643835616438356\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state= 1)\n",
    "rf.fit(X_train, y_train)\n",
    "score = rf.score(X_test, y_test)\n",
    "print(\"Random forest accuracy \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's introduce cross validation and param grid to find the best set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf accuracy 0.6631889183613322\n",
      "rf best params:  {'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "param_grid = {'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "               'max_depth': range(1, 6),\n",
    "               'n_estimators': [100, 300, 400]}\n",
    "\n",
    "rf_cv = GridSearchCV(rf, param_grid, cv = kf)\n",
    "rf_cv.fit(X_train, y_train)\n",
    "print('rf accuracy', rf_cv.best_score_)\n",
    "print('rf best params: ', rf_cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may seem a little counterintuitive that the model now performs a tiny bit worse, but that's thanks to the cross validation. Now let's try this for every possible combination of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerset(s):\n",
    "   \"\"\"funcion that spits out every subset of a given set\"\"\"\n",
    "   all_sets = []\n",
    "   x = len(s)\n",
    "   for i in range(1 << x):\n",
    "       #print([s[j] for j in range(x) if (i & (1 << j))])\n",
    "       subsets = [s[j] for j in range(x) if (i & (1 << j))]\n",
    "       all_sets.append(subsets)\n",
    "   return(all_sets)\n",
    "     \n",
    "sets = powerset([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(df)):\n",
    "    X = df.iloc[:, sets[i]]\n",
    "    y = df['future result']\n",
    "    list = []\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1, stratify= y)\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "    rf = RandomForestClassifier()\n",
    "    param_grid = {'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "               'max_depth': range(1, 6),\n",
    "               'n_estimators': [100, 300, 400]}\n",
    "    rf_cv = GridSearchCV(rf, param_grid, cv = kf)\n",
    "    rf_cv.fit(X_train, y_train)\n",
    "    list.append([rf_cv.best_score_, rf_cv.best_params_])\n",
    "\n",
    "df_r = pd.DataFrame(list)\n",
    "df_r.to_csv('Random Forest Full Test.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
